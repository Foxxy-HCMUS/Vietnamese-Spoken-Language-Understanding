{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install datasets[audio] -q\n!pip uninstall transformers -y\n!pip install transformers==4.20.0 \n!pip install pyctcdecode==v0.1.0\n!pip install https://github.com/kpu/kenlm/archive/master.zip\n!pip install jiwer -q","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:44:56.785817Z","iopub.execute_input":"2023-09-09T18:44:56.786243Z","iopub.status.idle":"2023-09-09T18:47:11.644236Z","shell.execute_reply.started":"2023-09-09T18:44:56.786213Z","shell.execute_reply":"2023-09-09T18:47:11.642909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\nfrom datasets import load_dataset, load_metric, Dataset#, Audio\nimport soundfile as sf\nimport pandas as pd\nfrom transformers.file_utils import cached_path, hf_bucket_url\nimport os, zipfile\nimport kenlm\nfrom pyctcdecode import Alphabet, BeamSearchDecoderCTC, LanguageModel\nimport IPython\nimport torchaudio\nimport torch\nimport json\n\nwer_metric = load_metric(\"wer\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-09T18:47:11.646665Z","iopub.execute_input":"2023-09-09T18:47:11.647135Z","iopub.status.idle":"2023-09-09T18:47:25.190136Z","shell.execute_reply.started":"2023-09-09T18:47:11.647099Z","shell.execute_reply":"2023-09-09T18:47:25.189156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cache_dir = './cache/'\nprocessor = Wav2Vec2Processor.from_pretrained(\"foxxy-hm/wav2vec2-base-finetune-vi-v6\", cache_dir=cache_dir)\nmodel = Wav2Vec2ForCTC.from_pretrained(\"foxxy-hm/wav2vec2-base-finetune-vi-v6\", cache_dir=cache_dir)\n# model.to(\"cpu\")\n# lm_file = hf_bucket_url(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\", filename='vi_lm_4grams.bin.zip')\n# lm_file = cached_path(lm_file,cache_dir=cache_dir)\n# with zipfile.ZipFile(lm_file, 'r') as zip_ref:\n#     zip_ref.extractall(cache_dir)\n# lm_file = cache_dir + 'vi_lm_4grams.bin'","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:47:25.191718Z","iopub.execute_input":"2023-09-09T18:47:25.192471Z","iopub.status.idle":"2023-09-09T18:47:52.428392Z","shell.execute_reply.started":"2023-09-09T18:47:25.192436Z","shell.execute_reply":"2023-09-09T18:47:52.427355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data and preprocess","metadata":{}},{"cell_type":"code","source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n\n    df = pd.DataFrame(dataset[picks])\n    display(HTML(df.to_html()))","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:47:52.431116Z","iopub.execute_input":"2023-09-09T18:47:52.431551Z","iopub.status.idle":"2023-09-09T18:47:52.438832Z","shell.execute_reply.started":"2023-09-09T18:47:52.431516Z","shell.execute_reply":"2023-09-09T18:47:52.437755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/soict2023-slu/SLU/public_test/public_test/\"","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:47:52.440339Z","iopub.execute_input":"2023-09-09T18:47:52.440734Z","iopub.status.idle":"2023-09-09T18:47:52.449240Z","shell.execute_reply.started":"2023-09-09T18:47:52.440594Z","shell.execute_reply":"2023-09-09T18:47:52.448516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ntest_ds = Dataset.from_dict({\n    \"file\": [path + i for i in os.listdir(path)]\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:47:52.450618Z","iopub.execute_input":"2023-09-09T18:47:52.454157Z","iopub.status.idle":"2023-09-09T18:47:52.973242Z","shell.execute_reply.started":"2023-09-09T18:47:52.454114Z","shell.execute_reply":"2023-09-09T18:47:52.972271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import soundfile as sf\n\ndef speech_file_to_array_fn(batch):\n    speech_array, sampling_rate = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    batch[\"sampling_rate\"] = sampling_rate\n    return batch","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:47:52.976441Z","iopub.execute_input":"2023-09-09T18:47:52.977985Z","iopub.status.idle":"2023-09-09T18:47:53.483160Z","shell.execute_reply.started":"2023-09-09T18:47:52.977944Z","shell.execute_reply":"2023-09-09T18:47:53.482077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = test_ds.map(speech_file_to_array_fn)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:47:53.484520Z","iopub.execute_input":"2023-09-09T18:47:53.485185Z","iopub.status.idle":"2023-09-09T18:48:06.768155Z","shell.execute_reply.started":"2023-09-09T18:47:53.485150Z","shell.execute_reply":"2023-09-09T18:48:06.767185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_random_elements(test_ds, num_examples=2)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:48:06.769743Z","iopub.execute_input":"2023-09-09T18:48:06.770116Z","iopub.status.idle":"2023-09-09T18:48:06.890637Z","shell.execute_reply.started":"2023-09-09T18:48:06.770085Z","shell.execute_reply":"2023-09-09T18:48:06.889536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 2-gram model","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:48:06.894363Z","iopub.execute_input":"2023-09-09T18:48:06.894651Z","iopub.status.idle":"2023-09-09T18:48:06.902922Z","shell.execute_reply.started":"2023-09-09T18:48:06.894626Z","shell.execute_reply":"2023-09-09T18:48:06.901836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars_to_ignore_regex = '[\\?\\.\\!\\-\\;\\:\\\"\\“\\‘\\”\\�\\।\\’]'\nimport json\nimport re\ntrain = []\nwith open('/kaggle/input/soict2023-slu/SLU/train_20230909.jsonl') as f:\n    for line in f.readlines():\n        sample = json.loads(line)[\"sentence\"]\n        sample = re.sub(chars_to_ignore_regex, '', sample.replace(\",\", \" \"))\n        train.append(sample)\n\nwith open('/kaggle/working/text.txt', 'w') as f:\n    f.write(\" \".join(train))","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:48:06.904345Z","iopub.execute_input":"2023-09-09T18:48:06.904856Z","iopub.status.idle":"2023-09-09T18:48:07.040126Z","shell.execute_reply.started":"2023-09-09T18:48:06.904822Z","shell.execute_reply":"2023-09-09T18:48:07.038936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! sudo apt -y install build-essential cmake libboost-system-dev libboost-thread-dev libboost-program-options-dev libboost-test-dev libeigen3-dev zlib1g-dev libbz2-dev liblzma-dev\n! wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz\n! mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n! ls kenlm/build/bin\n! kenlm/build/bin/lmplz -o 2 < \"text.txt\" > \"2gram.arpa\"","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:48:07.041631Z","iopub.execute_input":"2023-09-09T18:48:07.042073Z","iopub.status.idle":"2023-09-09T18:50:42.428441Z","shell.execute_reply.started":"2023-09-09T18:48:07.042032Z","shell.execute_reply":"2023-09-09T18:50:42.427241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create 3-gram model","metadata":{}},{"cell_type":"code","source":"! kenlm/build/bin/lmplz -o 3 < \"text.txt\" > \"3gram.arpa\"","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:50:42.430365Z","iopub.execute_input":"2023-09-09T18:50:42.430788Z","iopub.status.idle":"2023-09-09T18:50:45.910502Z","shell.execute_reply.started":"2023-09-09T18:50:42.430749Z","shell.execute_reply":"2023-09-09T18:50:45.909355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Xem 30 dòng đầu tiên ","metadata":{}},{"cell_type":"code","source":"!head -30 2gram.arpa","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:50:45.913205Z","iopub.execute_input":"2023-09-09T18:50:45.913600Z","iopub.status.idle":"2023-09-09T18:50:46.952175Z","shell.execute_reply.started":"2023-09-09T18:50:45.913563Z","shell.execute_reply":"2023-09-09T18:50:46.950765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 2-gram đã bao gồm chính xác `<unk>` và `<s>` token, nhưng lại không có token `<\\s>` \n- Do đó, ta sẽ thêm `end-of-sentence` token vào bằng cách thêm dòng `0 </s> -0.17968792` vào dưới`begin-of-sentence` token và tăng ngram 1 count lên 1. ","metadata":{}},{"cell_type":"code","source":"def fix_ngrams(n_grams):\n    with open(f\"{n_grams}.arpa\", \"r\") as read_file, open(f\"{n_grams}_correct.arpa\", \"w\") as write_file:\n        has_added_eos = False\n        for line in read_file:\n            if not has_added_eos and \"ngram 1=\" in line:\n                count=line.strip().split(\"=\")[-1]\n                write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n            elif not has_added_eos and \"<s>\" in line:\n                write_file.write(line)\n                write_file.write(line.replace(\"<s>\", \"</s>\"))\n                has_added_eos = True\n            else:\n                write_file.write(line)\n\nfix_ngrams(\"2gram\")\nfix_ngrams(\"3gram\")","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:50:46.954213Z","iopub.execute_input":"2023-09-09T18:50:46.954953Z","iopub.status.idle":"2023-09-09T18:50:46.991351Z","shell.execute_reply.started":"2023-09-09T18:50:46.954912Z","shell.execute_reply":"2023-09-09T18:50:46.990406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import kenlm\nngram_model_2 = kenlm.LanguageModel('./2gram_correct.arpa')\nngram_model_3 = kenlm.LanguageModel('./3gram_correct.arpa')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:50:46.992805Z","iopub.execute_input":"2023-09-09T18:50:46.993372Z","iopub.status.idle":"2023-09-09T18:50:47.018521Z","shell.execute_reply.started":"2023-09-09T18:50:46.993336Z","shell.execute_reply":"2023-09-09T18:50:47.017608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head -20 2gram_correct.arpa","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:50:47.019814Z","iopub.execute_input":"2023-09-09T18:50:47.020768Z","iopub.status.idle":"2023-09-09T18:50:48.039352Z","shell.execute_reply.started":"2023-09-09T18:50:47.020731Z","shell.execute_reply":"2023-09-09T18:50:48.038135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load N-Gram LM","metadata":{}},{"cell_type":"code","source":"def get_decoder_ngram_model(tokenizer, ngram_lm_path):\n    vocab_dict = tokenizer.get_vocab()\n    sort_vocab = sorted((value, key) for (key, value) in vocab_dict.items())\n    vocab = [x[1] for x in sort_vocab][:-2]\n    vocab_list = vocab\n    # convert ctc blank character representation\n    vocab_list[tokenizer.pad_token_id] = \"\"\n    # replace special characters\n    vocab_list[tokenizer.unk_token_id] = \"\"\n#     vocab_list[tokenizer.bos_token_id] = \"\"\n#     vocab_list[tokenizer.eos_token_id] = \"\"\n    # convert space character representation\n    vocab_list[tokenizer.word_delimiter_token_id] = \" \"\n    # specify ctc blank char index, since conventially it is the last entry of the logit matrix\n    alphabet = Alphabet.build_alphabet(vocab_list, ctc_token_idx=tokenizer.pad_token_id)\n    lm_model = kenlm.Model(ngram_lm_path)\n    decoder = BeamSearchDecoderCTC(alphabet,\n                                   language_model=LanguageModel(lm_model))\n    return decoder","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:53:05.239799Z","iopub.execute_input":"2023-09-09T18:53:05.240212Z","iopub.status.idle":"2023-09-09T18:53:05.248360Z","shell.execute_reply.started":"2023-09-09T18:53:05.240182Z","shell.execute_reply":"2023-09-09T18:53:05.247151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ngram_lm_model_2 = get_decoder_ngram_model(processor.tokenizer, \"./2gram_correct.arpa\")\nngram_lm_model_3 = get_decoder_ngram_model(processor.tokenizer, \"./3gram_correct.arpa\")","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:53:07.161583Z","iopub.execute_input":"2023-09-09T18:53:07.162277Z","iopub.status.idle":"2023-09-09T18:53:07.182193Z","shell.execute_reply.started":"2023-09-09T18:53:07.162240Z","shell.execute_reply":"2023-09-09T18:53:07.181165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def map_to_result(batch):\n    model.to(\"cuda\")\n    input_values = processor(\n      batch[\"speech\"],\n      sampling_rate=batch[\"sampling_rate\"],\n      return_tensors=\"pt\"\n    ).input_values.to(\"cuda\")\n\n    with torch.no_grad():\n        logits = model(input_values).logits\n\n    pred_ids = torch.argmax(logits, dim=-1)\n    batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n    batch[\"pred_str_with_beam_search_2\"] = ngram_lm_model_2.decode(logits[0].cpu().detach().numpy(), beam_width=500)\n    batch[\"pred_str_with_beam_search_3\"] = ngram_lm_model_3.decode(logits[0].cpu().detach().numpy(), beam_width=500)\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:53:14.458843Z","iopub.execute_input":"2023-09-09T18:53:14.459942Z","iopub.status.idle":"2023-09-09T18:53:14.469382Z","shell.execute_reply.started":"2023-09-09T18:53:14.459893Z","shell.execute_reply":"2023-09-09T18:53:14.467616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = test_ds.map(map_to_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:53:16.514834Z","iopub.execute_input":"2023-09-09T18:53:16.515204Z","iopub.status.idle":"2023-09-09T18:56:59.812042Z","shell.execute_reply.started":"2023-09-09T18:53:16.515174Z","shell.execute_reply":"2023-09-09T18:56:59.810970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_random_elements(results.remove_columns([\"speech\", \"sampling_rate\"]))","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:59:49.509857Z","iopub.execute_input":"2023-09-09T18:59:49.510231Z","iopub.status.idle":"2023-09-09T18:59:49.523753Z","shell.execute_reply.started":"2023-09-09T18:59:49.510201Z","shell.execute_reply":"2023-09-09T18:59:49.522602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.to_pandas().to_csv(\"inference_stage1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T18:56:59.830681Z","iopub.execute_input":"2023-09-09T18:56:59.831126Z","iopub.status.idle":"2023-09-09T18:57:00.583822Z","shell.execute_reply.started":"2023-09-09T18:56:59.831092Z","shell.execute_reply":"2023-09-09T18:57:00.582817Z"},"trusted":true},"execution_count":null,"outputs":[]}]}