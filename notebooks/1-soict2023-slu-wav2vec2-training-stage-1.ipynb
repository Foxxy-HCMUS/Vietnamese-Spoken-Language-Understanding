{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Libraries","metadata":{"id":"RMybJzFNNk7u"}},{"cell_type":"code","source":"# !pip install huggingface_hub > /dev/null\n# !pip install git+https://github.com/huggingface/transformers.git > /dev/null\n# !pip install accelerate -U > /dev/null\n!pip install datasets==2.8.0 > /dev/null\n!pip install jiwer > /dev/null\n# !pip uninstall wandb -y","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:35:21.223811Z","iopub.execute_input":"2023-09-14T10:35:21.224282Z","iopub.status.idle":"2023-09-14T10:35:48.559826Z","shell.execute_reply.started":"2023-09-14T10:35:21.224248Z","shell.execute_reply":"2023-09-14T10:35:48.558549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Detect hardware, return appropriate distribution strategy\n# import tensorflow as tf\n# try:\n#     # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n#     print('Running on TPU ', tpu.master())\n# except ValueError:\n#     tpu = None\n\n# if tpu:\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# else:\n#     strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n# print(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:12:39.754127Z","iopub.execute_input":"2023-09-12T10:12:39.754518Z","iopub.status.idle":"2023-09-12T10:12:39.760279Z","shell.execute_reply.started":"2023-09-12T10:12:39.754481Z","shell.execute_reply":"2023-09-12T10:12:39.759262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hugging_face_key\")\nlogin(secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:35:48.563000Z","iopub.execute_input":"2023-09-14T10:35:48.563378Z","iopub.status.idle":"2023-09-14T10:35:49.143932Z","shell.execute_reply.started":"2023-09-14T10:35:48.563342Z","shell.execute_reply":"2023-09-14T10:35:49.142816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!apt install git-lfs","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:35:49.145349Z","iopub.execute_input":"2023-09-14T10:35:49.145975Z","iopub.status.idle":"2023-09-14T10:35:51.599763Z","shell.execute_reply.started":"2023-09-14T10:35:49.145938Z","shell.execute_reply":"2023-09-14T10:35:51.598465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip uninstall transformers -y\n# !pip install transformers==4.20.0\n# !pip install https://github.com/kpu/kenlm/archive/master.zip\n# !pip install pyctcdecode\n\n# from transformers.file_utils import cached_path, hf_bucket_url\n# from importlib.machinery import SourceFileLoader\n# from transformers import Wav2Vec2ProcessorWithLM","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:12:43.491361Z","iopub.execute_input":"2023-09-12T10:12:43.491755Z","iopub.status.idle":"2023-09-12T10:12:43.497353Z","shell.execute_reply.started":"2023-09-12T10:12:43.491715Z","shell.execute_reply":"2023-09-12T10:12:43.495809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.lib.display import Audio\nimport torchaudio\nimport torch\nfrom datasets import load_dataset, load_from_disk, Dataset, DatasetDict\nimport json\nimport pandas as pd\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nfrom datasets import load_metric\nwer_metric = load_metric(\"wer\")","metadata":{"id":"4U1W_hALfofM","execution":{"iopub.status.busy":"2023-09-14T10:35:51.603078Z","iopub.execute_input":"2023-09-14T10:35:51.603506Z","iopub.status.idle":"2023-09-14T10:35:56.095324Z","shell.execute_reply.started":"2023-09-14T10:35:51.603469Z","shell.execute_reply":"2023-09-14T10:35:56.094324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load datasets","metadata":{"id":"yBCOmIPlNp44"}},{"cell_type":"code","source":"# data = load_dataset(\"foxxy-hm/slu-augmented-data\")\ntrain = load_from_disk(\"/kaggle/input/soict2023-slu-preprocess-and-augmentation-stage-1/data/train.dataset\", keep_in_memory=True)\nvalid = load_from_disk(\"/kaggle/input/soict2023-slu-preprocess-and-augmentation-stage-1/data/valid.dataset\", keep_in_memory=True)\ndata = DatasetDict({\n    \"train\": train,\n    \"valid\": valid\n})\ntrain.cleanup_cache_files()\nvalid.cleanup_cache_files()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:35:56.096689Z","iopub.execute_input":"2023-09-14T10:35:56.097587Z","iopub.status.idle":"2023-09-14T10:36:41.119548Z","shell.execute_reply.started":"2023-09-14T10:35:56.097548Z","shell.execute_reply":"2023-09-14T10:36:41.118638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:36:41.120985Z","iopub.execute_input":"2023-09-14T10:36:41.121314Z","iopub.status.idle":"2023-09-14T10:36:41.127799Z","shell.execute_reply.started":"2023-09-14T10:36:41.121280Z","shell.execute_reply":"2023-09-14T10:36:41.126935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\nfrom datasets import load_dataset\nimport soundfile as sf\nimport torch\n\ncache = \"./cache\"\nprocessor = Wav2Vec2Processor.from_pretrained(\"foxxy-hm/wav2vec2-base-finetune-vi-v6\")\n# model = Wav2Vec2ForCTC.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\",\n#                                        gradient_checkpointing=True,\n#                                         ctc_loss_reduction=\"mean\",\n#                                         pad_token_id=processor.tokenizer.pad_token_id)\n# model_name = \"nguyenvulebinh/wav2vec2-large-vi\"\nmodel_name = \"foxxy-hm/wav2vec2-base-finetune-vi-v6\"\nmodel = Wav2Vec2ForCTC.from_pretrained(model_name, pad_token_id=processor.tokenizer.pad_token_id, \n#                                       gradient_checkpointing=True,\n                                       ctc_loss_reduction=\"mean\",\n                                       vocab_size=len(processor.tokenizer.get_vocab())-2, # 110\n                                      ignore_mismatched_sizes=True)","metadata":{"id":"sr3TgoxQcr1y","outputId":"45e9c78a-5436-44df-e6a6-d32756418921","execution":{"iopub.status.busy":"2023-09-14T10:45:59.883722Z","iopub.execute_input":"2023-09-14T10:45:59.884141Z","iopub.status.idle":"2023-09-14T10:46:04.361351Z","shell.execute_reply.started":"2023-09-14T10:45:59.884108Z","shell.execute_reply":"2023-09-14T10:46:04.360161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# processor.push_to_hub(\"wav2vec2-base-finetune-vi-v5\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:14:39.664833Z","iopub.execute_input":"2023-09-12T10:14:39.665137Z","iopub.status.idle":"2023-09-12T10:14:39.670624Z","shell.execute_reply.started":"2023-09-12T10:14:39.665109Z","shell.execute_reply":"2023-09-12T10:14:39.669344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kiểm tra rằng toàn bộ các samples có sampling rate là 16kHz. Sau đó, extract `input_values` from loaded audio file. Cuối cùng, encode the transcriptions thành label ids.","metadata":{"id":"Z5haIAgcaXHy"}},{"cell_type":"code","source":"def prepare_dataset(batch):\n    # check that all files have the correct sampling rate\n    assert (\n        len(set(batch[\"sampling_rate\"])) == 1\n    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n\n    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0], padding=\"longest\").input_values\n\n    with processor.as_target_processor():\n        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n    return batch","metadata":{"id":"NXXwG0jhZql6","execution":{"iopub.status.busy":"2023-09-12T10:14:39.672037Z","iopub.execute_input":"2023-09-12T10:14:39.672523Z","iopub.status.idle":"2023-09-12T10:14:39.683664Z","shell.execute_reply.started":"2023-09-12T10:14:39.672487Z","shell.execute_reply":"2023-09-12T10:14:39.682759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_prepared = data.map(prepare_dataset, remove_columns=data.column_names[\"train\"], batch_size=8, batched=True)\ndata.cleanup_cache_files()","metadata":{"id":"QHqWpGRTaRVK","outputId":"70787682-ceab-473c-eaaf-ee41a1246aad","execution":{"iopub.status.busy":"2023-09-12T10:14:39.685097Z","iopub.execute_input":"2023-09-12T10:14:39.685503Z","iopub.status.idle":"2023-09-12T10:21:07.095769Z","shell.execute_reply.started":"2023-09-12T10:14:39.685465Z","shell.execute_reply":"2023-09-12T10:21:07.094649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Zero-shot inference","metadata":{"id":"HqWxYPTNcSHG"}},{"cell_type":"code","source":"# def map_to_result(batch):\n#   model.to(\"cuda\")\n#   input_values = processor(\n#       batch[\"speech\"],\n#       sampling_rate=batch[\"sampling_rate\"],\n#       return_tensors=\"pt\",\n#         padding=\"longest\"\n#   ).input_values.to(\"cuda\")\n\n#   with torch.no_grad():\n#     logits = model(input_values).logits\n\n#   pred_ids = torch.argmax(logits, dim=-1)\n#   batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n\n#   return batch","metadata":{"id":"NoSHhFtEaxFU","execution":{"iopub.status.busy":"2023-09-12T10:21:07.097178Z","iopub.execute_input":"2023-09-12T10:21:07.097626Z","iopub.status.idle":"2023-09-12T10:21:07.102573Z","shell.execute_reply.started":"2023-09-12T10:21:07.097592Z","shell.execute_reply":"2023-09-12T10:21:07.101481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results = data[\"test\"].map(map_to_result)","metadata":{"id":"w_RFaH8xdFJp","execution":{"iopub.status.busy":"2023-09-12T10:21:07.104046Z","iopub.execute_input":"2023-09-12T10:21:07.104650Z","iopub.status.idle":"2023-09-12T10:21:07.114242Z","shell.execute_reply.started":"2023-09-12T10:21:07.104616Z","shell.execute_reply":"2023-09-12T10:21:07.113327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_random_elements(results.remove_columns([\"speech\", \"sampling_rate\"]))","metadata":{"id":"bRs2VJhSwjUD","execution":{"iopub.status.busy":"2023-09-12T10:21:07.117264Z","iopub.execute_input":"2023-09-12T10:21:07.117973Z","iopub.status.idle":"2023-09-12T10:21:07.127563Z","shell.execute_reply.started":"2023-09-12T10:21:07.117947Z","shell.execute_reply":"2023-09-12T10:21:07.126568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=results[\"pred_str\"], references=results[\"target_text\"])))","metadata":{"id":"qYYhoBNpVwDq","outputId":"3df9533a-8f9f-4342-fb30-b23813688280","execution":{"iopub.status.busy":"2023-09-12T10:21:07.128740Z","iopub.execute_input":"2023-09-12T10:21:07.129693Z","iopub.status.idle":"2023-09-12T10:21:07.140172Z","shell.execute_reply.started":"2023-09-12T10:21:07.129657Z","shell.execute_reply":"2023-09-12T10:21:07.139211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nTest WER: 0.407\n```","metadata":{"id":"aZTSmWxDg9Bf"}},{"cell_type":"markdown","source":"# Training Model","metadata":{"id":"yLRkqdERa8ig"}},{"cell_type":"markdown","source":"## Setup Trainer","metadata":{"id":"C_8gMPTxxlMO"}},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    \"\"\"\n    Data collator that will dynamically pad the inputs received.\n    Args:\n        processor (:class:`~transformers.Wav2Vec2Processor`)\n            The processor used for proccessing the data.\n        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n            among:\n            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n              sequence if provided).\n            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n              maximum acceptable input length for the model if that argument is not provided.\n            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n              different lengths).\n        max_length (:obj:`int`, `optional`):\n            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n        max_length_labels (:obj:`int`, `optional`):\n            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n        pad_to_multiple_of (:obj:`int`, `optional`):\n            If set will pad the sequence to a multiple of the provided value.\n            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n            7.5 (Volta).\n    \"\"\"\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n    max_length: Optional[int] = None\n    max_length_labels: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    pad_to_multiple_of_labels: Optional[int] = None\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lenghts and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                max_length=self.max_length_labels,\n                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"id":"KKgZLdfYxjdW","execution":{"iopub.status.busy":"2023-09-12T10:21:07.143706Z","iopub.execute_input":"2023-09-12T10:21:07.143962Z","iopub.status.idle":"2023-09-12T10:21:07.157967Z","shell.execute_reply.started":"2023-09-12T10:21:07.143939Z","shell.execute_reply":"2023-09-12T10:21:07.156902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"id":"OjARawc3x4HN","execution":{"iopub.status.busy":"2023-09-12T10:21:07.159378Z","iopub.execute_input":"2023-09-12T10:21:07.159781Z","iopub.status.idle":"2023-09-12T10:21:07.172161Z","shell.execute_reply.started":"2023-09-12T10:21:07.159750Z","shell.execute_reply":"2023-09-12T10:21:07.171250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"id":"oRRDtV5Kx9wZ","execution":{"iopub.status.busy":"2023-09-12T10:21:07.173545Z","iopub.execute_input":"2023-09-12T10:21:07.174038Z","iopub.status.idle":"2023-09-12T10:21:07.187069Z","shell.execute_reply.started":"2023-09-12T10:21:07.174006Z","shell.execute_reply":"2023-09-12T10:21:07.186097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.freeze_feature_extractor()","metadata":{"id":"2U55FzDXyD2f","outputId":"0e4fd250-f11c-48b9-96cb-bce6b96468ea","execution":{"iopub.status.busy":"2023-09-12T10:21:07.188605Z","iopub.execute_input":"2023-09-12T10:21:07.189018Z","iopub.status.idle":"2023-09-12T10:21:07.199840Z","shell.execute_reply.started":"2023-09-12T10:21:07.188985Z","shell.execute_reply":"2023-09-12T10:21:07.198804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"id":"w1-9zjl9LtVE","outputId":"29e79c7f-d4e7-4340-bb53-eebc7bf94565","execution":{"iopub.status.busy":"2023-09-12T10:21:07.201483Z","iopub.execute_input":"2023-09-12T10:21:07.202633Z","iopub.status.idle":"2023-09-12T10:21:07.210066Z","shell.execute_reply.started":"2023-09-12T10:21:07.202599Z","shell.execute_reply":"2023-09-12T10:21:07.209010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n  output_dir=\"wav2vec2-base-finetune-vi-v6\",\n  group_by_length=True,\n  per_device_train_batch_size=16,\n  evaluation_strategy=\"steps\",\n  num_train_epochs=20,\n  fp16=True,\n  save_steps=500,\n  eval_steps=500,\n  logging_steps=500,\n  learning_rate=6e-5,\n  weight_decay=0.005,\n  warmup_steps=1000,\n  save_total_limit=2,\n  gradient_checkpointing=True,\n  push_to_hub=True\n)","metadata":{"id":"k9DMtgMFyUmS","execution":{"iopub.status.busy":"2023-09-14T10:47:33.063310Z","iopub.execute_input":"2023-09-14T10:47:33.063675Z","iopub.status.idle":"2023-09-14T10:47:33.075195Z","shell.execute_reply.started":"2023-09-14T10:47:33.063645Z","shell.execute_reply":"2023-09-14T10:47:33.074083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=data_prepared[\"train\"],\n    eval_dataset=data_prepared[\"valid\"],\n    tokenizer=processor.feature_extractor,\n)","metadata":{"id":"IVWJ0ft1yfLZ","outputId":"64be9ec1-f7ce-4688-ec59-7fb8d10da5db","execution":{"iopub.status.busy":"2023-09-12T10:21:07.336968Z","iopub.execute_input":"2023-09-12T10:21:07.337644Z","iopub.status.idle":"2023-09-12T10:21:18.107923Z","shell.execute_reply.started":"2023-09-12T10:21:07.337609Z","shell.execute_reply":"2023-09-12T10:21:18.106922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"DoZrooWzynTP","outputId":"2ed9d5bf-96e6-4fd8-d166-904b7ff2c143","execution":{"iopub.status.busy":"2023-09-12T10:21:18.109692Z","iopub.execute_input":"2023-09-12T10:21:18.110054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working\")\n# trainer.push_to_hub(\"wav2vec2-base-finetune-vi-v5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# !pip install jiwer\n# from datasets import load_metric\n# wer_metric = load_metric(\"wer\")","metadata":{"id":"tgXxjgOLV1cT","outputId":"c1d83196-c7c6-4524-d377-4152da1590f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2Config\n# import torch\n\n\n# processor = Wav2Vec2Processor.from_pretrained(\"/kaggle/working/\", local_files_only=True)\n# model = Wav2Vec2ForCTC.from_pretrained(\"/kaggle/working/\", local_files_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import random\n\n# model.to(\"cuda\")\n# n = random.randint(0, len(data[\"valid\"]))\n# batch = data[\"valid\"][n]\n# input_values = processor(\n#   batch[\"speech\"],\n#   sampling_rate=batch[\"sampling_rate\"],\n#   return_tensors=\"pt\"\n# ).input_values.to(\"cuda\")\n\n# with torch.no_grad():\n#     logits = model(input_values).logits\n\n# pred_ids = torch.argmax(logits, dim=-1)\n# pred = processor.batch_decode(pred_ids)[0]\n# print(n, pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}