{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras_preprocessing\n!pip install pandarallel\nfrom pandarallel import pandarallel\npandarallel.initialize(progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:17:32.715047Z","iopub.execute_input":"2023-09-10T12:17:32.715443Z","iopub.status.idle":"2023-09-10T12:18:06.316497Z","shell.execute_reply.started":"2023-09-10T12:17:32.715411Z","shell.execute_reply":"2023-09-10T12:18:06.315229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Test Data\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import load_from_disk, load_dataset\n# test_infer_stage1 = load_dataset(\"foxxy-hm/slu-inference-stage1\", split=\"train\")\n# test_infer_stage1 = load_from_disk(\"/kaggle/input/soict-2023-wav2vec2-n-gram-inference-stage-1\")\n# test_df = test_infer_stage1.to_pandas()\n\n# test_df = pd.read_csv(\"/kaggle/input/bi-model/inference_stage1 v3.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/soict-2023-wav2vec2-n-gram-inference-stage-1/inference_stage1.csv\")\ntest_df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T12:18:06.319272Z","iopub.execute_input":"2023-09-10T12:18:06.320273Z","iopub.status.idle":"2023-09-10T12:18:07.541865Z","shell.execute_reply.started":"2023-09-10T12:18:06.320196Z","shell.execute_reply":"2023-09-10T12:18:07.540680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Models","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:07.543612Z","iopub.execute_input":"2023-09-10T12:18:07.544339Z","iopub.status.idle":"2023-09-10T12:18:08.652246Z","shell.execute_reply.started":"2023-09-10T12:18:07.544300Z","shell.execute_reply":"2023-09-10T12:18:08.650813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir data","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:08.653979Z","iopub.execute_input":"2023-09-10T12:18:08.654362Z","iopub.status.idle":"2023-09-10T12:18:09.753091Z","shell.execute_reply.started":"2023-09-10T12:18:08.654331Z","shell.execute_reply":"2023-09-10T12:18:09.751857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/output-training-stage-2-v2-08/*.py /kaggle/working/\n!cp /kaggle/input/output-training-stage-2-v2-08/data/train_stage2.jsonl /kaggle/working/data/\n!cp /kaggle/input/output-training-stage-2-v2-08/data/valid_stage2.jsonl /kaggle/working/data/","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:09.757130Z","iopub.execute_input":"2023-09-10T12:18:09.757660Z","iopub.status.idle":"2023-09-10T12:18:13.128645Z","shell.execute_reply.started":"2023-09-10T12:18:09.757625Z","shell.execute_reply":"2023-09-10T12:18:13.126994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \nfrom model import *\nslot_model = torch.load(\"/kaggle/input/output-training-stage-2-v2-08/model_slot_best.ckpt\", map_location=torch.device('cpu'))\nintent_model = torch.load(\"/kaggle/input/output-training-stage-2-v2-08/model_intent_best.ckpt\", map_location=torch.device('cpu'))\n# slot_model = torch.load(\"/kaggle/input/soict2023-slu-training-stage-2-v2/model_slot_best.ckpt\", map_location=torch.device('cpu'))\n# intent_model = torch.load(\"/kaggle/input/soict2023-slu-training-stage-2-v2/model_intent_best.ckpt\", map_location=torch.device('cpu'))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:13.130503Z","iopub.execute_input":"2023-09-10T12:18:13.130997Z","iopub.status.idle":"2023-09-10T12:18:17.219917Z","shell.execute_reply.started":"2023-09-10T12:18:13.130960Z","shell.execute_reply":"2023-09-10T12:18:17.218638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    display(HTML(df.to_html()))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:17.221728Z","iopub.execute_input":"2023-09-10T12:18:17.222774Z","iopub.status.idle":"2023-09-10T12:18:17.231914Z","shell.execute_reply.started":"2023-09-10T12:18:17.222731Z","shell.execute_reply":"2023-09-10T12:18:17.230860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_random_elements(test_infer_stage1, num_examples=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:09:34.878181Z","iopub.execute_input":"2023-09-10T12:09:34.878649Z","iopub.status.idle":"2023-09-10T12:09:34.889411Z","shell.execute_reply.started":"2023-09-10T12:09:34.878622Z","shell.execute_reply":"2023-09-10T12:09:34.888693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def labels2token(labels, tokens):\n    result = []\n    current_label = None\n    current_tokens = []\n\n    for label, token in zip(labels, tokens):\n        if label != 'O':\n            if current_label is None:\n                current_label = label\n            current_tokens.append(token)\n        else:\n            if current_label is not None:\n                result.append({\"type\": current_label, \"filler\": ' '.join(current_tokens)})\n                current_label = None\n                current_tokens = []\n\n    # Append the last label if it exists\n    if current_label is not None:\n        result.append({\"type\": current_label, \"filler\": ' '.join(current_tokens)})\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:17.233387Z","iopub.execute_input":"2023-09-10T12:18:17.234008Z","iopub.status.idle":"2023-09-10T12:18:17.250747Z","shell.execute_reply.started":"2023-09-10T12:18:17.233978Z","shell.execute_reply":"2023-09-10T12:18:17.249600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from make_dict import idx2intent, idx2slot, idx2word, word2idx\nfrom keras_preprocessing.sequence import pad_sequences\nimport torch.nn.functional as F \nimport torch\nimport utils\n# torch.multiprocessing.set_start_method('spawn')\n\ndevice=\"cpu\"\ndef map_to_result(batch):\n#     \n\n    sentences = batch[\"pred_str\"]\n    real_len_test = [batch[\"sentence_len\"]]\n    # Chuyển các câu về dạng vector of index\n    sentence_idx = [word2idx.get(w, word2idx['UNK']) for w in sentences]\n\n    # Padding các câu về max_len\n    while len(sentence_idx) < 50:\n        sentence_idx.append(word2idx[\"PAD\"])\n        \n    x_test = torch.tensor(sentence_idx).unsqueeze(0).to(device)\n#     print(x_test)\n    mask_test = utils.make_mask(real_len_test, batch=1).to(device)\n    # Slot model generate hs_test and intent model generate hi_test\n    hs_test = slot_model.enc(x_test)\n    hi_test = intent_model.enc(x_test)\n\n    # Slot\n    slot_logits_test = slot_model.dec(hs_test, hi_test)\n    log_slot_logits_test = utils.masked_log_softmax(slot_logits_test, mask_test, dim=-1)\n    slot_pred_test = torch.argmax(log_slot_logits_test, dim=-1)\n    # Intent\n    intent_logits_test = intent_model.dec(hi_test, hs_test, real_len_test)\n    log_intent_logits_test = F.log_softmax(intent_logits_test, dim=-1)\n    res_test = torch.argmax(log_intent_logits_test, dim=-1)\n    \n#     print(\"Itent: \")\n#     print(\"Predict: \", idx2intent[res_test.item()])\n    \n#     print(\"Slot: \")\n    slot_pred_test = slot_pred_test[0][:real_len_test[0]]\n\n    slot_pred_test = [int(item) for item in slot_pred_test]\n    slot_pred_test = [idx2slot[item] for item in slot_pred_test]\n#     print(\"Predict: \" , slot_pred_test)\n#     print(\"Sentence: \", sentences)\n#     print(\"=================\")\n    return {\"intent\": idx2intent[res_test.item()], \n                 \"entities\": labels2token(slot_pred_test, sentences),\n                 \"file\": batch[\"file\"].split(\"/\")[-1]}\n    \nimport re\nchars_to_ignore_regex = '[\\`\\'\\?\\.\\!\\-\\;\\/\"]'\ndef remove_special_characters(x):\n    x = x.lower().strip()\n    x = re.sub(\",\", \" \", x)\n    x = re.sub(chars_to_ignore_regex, '', x)\n    return x\n\ndef processing(x):\n    x = remove_special_characters(x)\n    return x.split()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:17.252175Z","iopub.execute_input":"2023-09-10T12:18:17.252599Z","iopub.status.idle":"2023-09-10T12:18:17.273950Z","shell.execute_reply.started":"2023-09-10T12:18:17.252567Z","shell.execute_reply":"2023-09-10T12:18:17.272705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Processing for base model","metadata":{}},{"cell_type":"code","source":"test_df[\"pred_str\"] = test_df[\"pred_str\"].parallel_apply(processing)\ntest_df[\"pred_str\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:17.276044Z","iopub.execute_input":"2023-09-10T12:18:17.276525Z","iopub.status.idle":"2023-09-10T12:18:17.460893Z","shell.execute_reply.started":"2023-09-10T12:18:17.276485Z","shell.execute_reply":"2023-09-10T12:18:17.459524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"sentence_len\"] = test_df[\"pred_str\"].apply(len)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:18:17.462603Z","iopub.execute_input":"2023-09-10T12:18:17.462962Z","iopub.status.idle":"2023-09-10T12:18:17.471266Z","shell.execute_reply.started":"2023-09-10T12:18:17.462930Z","shell.execute_reply":"2023-09-10T12:18:17.469913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Result for base model","metadata":{}},{"cell_type":"code","source":"results = test_df.apply(map_to_result, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:09:35.087434Z","iopub.execute_input":"2023-09-10T12:09:35.087977Z","iopub.status.idle":"2023-09-10T12:10:46.881219Z","shell.execute_reply.started":"2023-09-10T12:09:35.087950Z","shell.execute_reply":"2023-09-10T12:10:46.880133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.sample(5).values","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:10:46.882684Z","iopub.execute_input":"2023-09-10T12:10:46.883078Z","iopub.status.idle":"2023-09-10T12:10:46.891178Z","shell.execute_reply.started":"2023-09-10T12:10:46.883045Z","shell.execute_reply":"2023-09-10T12:10:46.890139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir infer_without_lm","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:10:46.892616Z","iopub.execute_input":"2023-09-10T12:10:46.893632Z","iopub.status.idle":"2023-09-10T12:10:47.888400Z","shell.execute_reply.started":"2023-09-10T12:10:46.893606Z","shell.execute_reply":"2023-09-10T12:10:47.886861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('infer_without_lm/predictions.jsonl', 'w', encoding='utf-8') as json_file:\n    for i in results:\n        json.dump(i, json_file, ensure_ascii=False)\n        json_file.write('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:10:47.890516Z","iopub.execute_input":"2023-09-10T12:10:47.890901Z","iopub.status.idle":"2023-09-10T12:10:47.950606Z","shell.execute_reply.started":"2023-09-10T12:10:47.890871Z","shell.execute_reply":"2023-09-10T12:10:47.949546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Processing for base model + 2-gram","metadata":{}},{"cell_type":"code","source":"test_df[\"pred_str_with_beam_search_2\"] = test_df[\"pred_str_with_beam_search_2\"].parallel_apply(processing)\ntest_df[\"pred_str_with_beam_search_2\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:10:47.952173Z","iopub.execute_input":"2023-09-10T12:10:47.953009Z","iopub.status.idle":"2023-09-10T12:10:48.082542Z","shell.execute_reply.started":"2023-09-10T12:10:47.952980Z","shell.execute_reply":"2023-09-10T12:10:48.081244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Results for base model with LM","metadata":{}},{"cell_type":"code","source":"# results[0][6:652]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:10:48.084246Z","iopub.execute_input":"2023-09-10T12:10:48.084644Z","iopub.status.idle":"2023-09-10T12:10:48.090418Z","shell.execute_reply.started":"2023-09-10T12:10:48.084609Z","shell.execute_reply":"2023-09-10T12:10:48.089448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_to_result(batch):\n#     \n\n    sentences = batch[\"pred_str_with_beam_search_2\"]\n    real_len_test = [len(batch[\"pred_str_with_beam_search_2\"])]\n    # Chuyển các câu về dạng vector of index\n    sentence_idx = [word2idx.get(w, word2idx['UNK']) for w in sentences]\n\n    # Padding các câu về max_len\n    while len(sentence_idx) < 50:\n        sentence_idx.append(word2idx[\"PAD\"])\n        \n    x_test = torch.tensor(sentence_idx).unsqueeze(0).to(device)\n#     print(x_test)\n    mask_test = utils.make_mask(real_len_test, batch=1).to(device)\n    # Slot model generate hs_test and intent model generate hi_test\n    hs_test = slot_model.enc(x_test)\n    hi_test = intent_model.enc(x_test)\n\n    # Slot\n    slot_logits_test = slot_model.dec(hs_test, hi_test)\n    log_slot_logits_test = utils.masked_log_softmax(slot_logits_test, mask_test, dim=-1)\n    slot_pred_test = torch.argmax(log_slot_logits_test, dim=-1)\n    # Intent\n    intent_logits_test = intent_model.dec(hi_test, hs_test, real_len_test)\n    log_intent_logits_test = F.log_softmax(intent_logits_test, dim=-1)\n    res_test = torch.argmax(log_intent_logits_test, dim=-1)\n    \n#     print(\"Itent: \")\n#     print(\"Predict: \", idx2intent[res_test.item()])\n    \n#     print(\"Slot: \")\n    slot_pred_test = slot_pred_test[0][:real_len_test[0]]\n\n    slot_pred_test = [int(item) for item in slot_pred_test]\n    slot_pred_test = [idx2slot[item] for item in slot_pred_test]\n#     print(\"Predict: \" , slot_pred_test)\n#     print(\"Sentence: \", sentences)\n#     print(\"=================\")\n    return {\"intent\": idx2intent[res_test.item()], \n                 \"entities\": labels2token(slot_pred_test, sentences),\n                 \"file\": batch[\"file\"].split(\"/\")[-1]}\n\nresults = test_df.apply(map_to_result, axis=1)\nimport json","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:10:48.091939Z","iopub.execute_input":"2023-09-10T12:10:48.092296Z","iopub.status.idle":"2023-09-10T12:11:59.544442Z","shell.execute_reply.started":"2023-09-10T12:10:48.092266Z","shell.execute_reply":"2023-09-10T12:11:59.543366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\ntest_df[[\"pred_str\", \"pred_str_with_beam_search_2\"]].sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:11:59.545639Z","iopub.execute_input":"2023-09-10T12:11:59.545939Z","iopub.status.idle":"2023-09-10T12:11:59.563397Z","shell.execute_reply.started":"2023-09-10T12:11:59.545914Z","shell.execute_reply":"2023-09-10T12:11:59.562465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.loc[[361, 981, 978, 836]]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:11:59.564856Z","iopub.execute_input":"2023-09-10T12:11:59.565188Z","iopub.status.idle":"2023-09-10T12:11:59.590429Z","shell.execute_reply.started":"2023-09-10T12:11:59.565156Z","shell.execute_reply":"2023-09-10T12:11:59.589255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import IPython.display as ipd\n# import numpy as np\n# import random\n# import soundfile as sf\n\n# speech_array, sampling_rate = sf.read(\"/kaggle/input/soict2023-slu/SLU/public_test/public_test/BA1LQuAP7SlUPuOr8kIQ6Y4.wav\")\n# speech_array, sampling_rate = sf.read(\"/kaggle/input/soict2023-slu/SLU/public_test/public_test/4dNNfE4gAAKTkkxiFbqI3M0.wav\")\n# speech_array, sampling_rate = sf.read(\"/kaggle/input/soict2023-slu/SLU/public_test/public_test/hdZ72FGMiC86B5FYKYjGmJC.wav\")\n# st = \"/kaggle/input/soict2023-slu/SLU/public_test/public_test/6bTozd2qnF5j7wsn2HMYqLz.wav\"\n# speech_array, sampling_rate = sf.read(st)\n# rand_int = random.randint(0, len(results))\n\n# ipd.Audio(data=np.asarray(speech_array), autoplay=True, rate=16000)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:11:59.593797Z","iopub.execute_input":"2023-09-10T12:11:59.594158Z","iopub.status.idle":"2023-09-10T12:11:59.602193Z","shell.execute_reply.started":"2023-09-10T12:11:59.594133Z","shell.execute_reply":"2023-09-10T12:11:59.601171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir infer_with_lm","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:11:59.603834Z","iopub.execute_input":"2023-09-10T12:11:59.604323Z","iopub.status.idle":"2023-09-10T12:12:00.626709Z","shell.execute_reply.started":"2023-09-10T12:11:59.604288Z","shell.execute_reply":"2023-09-10T12:12:00.625151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('infer_with_lm/predictions2.jsonl', 'w', encoding='utf-8') as json_file:\n    for i in results:\n        json.dump(i, json_file, ensure_ascii=False)\n        json_file.write('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:12:00.628672Z","iopub.execute_input":"2023-09-10T12:12:00.629073Z","iopub.status.idle":"2023-09-10T12:12:00.689989Z","shell.execute_reply.started":"2023-09-10T12:12:00.629040Z","shell.execute_reply":"2023-09-10T12:12:00.689212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Base model with 3-gram","metadata":{}},{"cell_type":"code","source":"test_df[\"pred_str_with_beam_search_3\"] = test_df[\"pred_str_with_beam_search_3\"].parallel_apply(processing)\ntest_df[\"pred_str_with_beam_search_3\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:12:00.691131Z","iopub.execute_input":"2023-09-10T12:12:00.691417Z","iopub.status.idle":"2023-09-10T12:12:00.817411Z","shell.execute_reply.started":"2023-09-10T12:12:00.691394Z","shell.execute_reply":"2023-09-10T12:12:00.816262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_to_result(batch):\n#     \n\n    sentences = batch[\"pred_str_with_beam_search_3\"]\n    real_len_test = [len(batch[\"pred_str_with_beam_search_3\"])]\n    # Chuyển các câu về dạng vector of index\n    sentence_idx = [word2idx.get(w, word2idx['UNK']) for w in sentences]\n\n    # Padding các câu về max_len\n    while len(sentence_idx) < 50:\n        sentence_idx.append(word2idx[\"PAD\"])\n        \n    x_test = torch.tensor(sentence_idx).unsqueeze(0).to(device)\n#     print(x_test)\n    mask_test = utils.make_mask(real_len_test, batch=1).to(device)\n    # Slot model generate hs_test and intent model generate hi_test\n    hs_test = slot_model.enc(x_test)\n    hi_test = intent_model.enc(x_test)\n\n    # Slot\n    slot_logits_test = slot_model.dec(hs_test, hi_test)\n    log_slot_logits_test = utils.masked_log_softmax(slot_logits_test, mask_test, dim=-1)\n    slot_pred_test = torch.argmax(log_slot_logits_test, dim=-1)\n    # Intent\n    intent_logits_test = intent_model.dec(hi_test, hs_test, real_len_test)\n    log_intent_logits_test = F.log_softmax(intent_logits_test, dim=-1)\n    res_test = torch.argmax(log_intent_logits_test, dim=-1)\n    \n#     print(\"Itent: \")\n#     print(\"Predict: \", idx2intent[res_test.item()])\n    \n#     print(\"Slot: \")\n    slot_pred_test = slot_pred_test[0][:real_len_test[0]]\n\n    slot_pred_test = [int(item) for item in slot_pred_test]\n    slot_pred_test = [idx2slot[item] for item in slot_pred_test]\n#     print(\"Predict: \" , slot_pred_test)\n#     print(\"Sentence: \", sentences)\n#     print(\"=================\")\n    return {\"intent\": idx2intent[res_test.item()], \n                 \"entities\": labels2token(slot_pred_test, sentences),\n                 \"file\": batch[\"file\"].split(\"/\")[-1]}\n\nresults = test_df.apply(map_to_result, axis=1)\nwith open('infer_with_lm/predictions3.jsonl', 'w', encoding='utf-8') as json_file:\n    for i in results:\n        json.dump(i, json_file, ensure_ascii=False)\n        json_file.write('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T12:12:00.818873Z","iopub.execute_input":"2023-09-10T12:12:00.819169Z","iopub.status.idle":"2023-09-10T12:13:12.133711Z","shell.execute_reply.started":"2023-09-10T12:12:00.819143Z","shell.execute_reply":"2023-09-10T12:13:12.132670Z"},"trusted":true},"execution_count":null,"outputs":[]}]}